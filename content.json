{"meta":{"title":"Colin's Blog","subtitle":"","description":"个人博客","author":"Colin Lin","url":"http://linco.com"},"pages":[],"posts":[{"title":"K8S (Kubernetes) 集群搭建","slug":"Kubernetes 集群搭建","date":"2020-04-07T15:43:27.051Z","updated":"2020-04-08T12:52:20.979Z","comments":true,"path":"2020/04/07/Kubernetes 集群搭建/","link":"","permalink":"http://linco.com/2020/04/07/Kubernetes%20%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"","text":"本次教程，使用docker 18.09.9 和kubelet-1.16.4，要求centos7.6 以上版本 1.环境准备首先准备三台互通的机器(此处用的是虚拟机)，CPU必须2核以上，内存master节点最好2G及以上： 宿主机名称 IP CPU/内存 备注 linco-centos73 192.168.31.223 2核/2G master linco-centos71 192.168.31.222 2核/2G work node linco-centos7 192.168.31.221 2核/2G work node 1.1 设置主机名 及 ip 解析如果机器名为localhost,则可以执行以下命令修改hostname: 12# 修改 hostnamehostnamectl set-hostname your_host_name 配置hostname对应ip解析： 12345sudo vi /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.31.222 linco-centos72 #添加ip解析 1.2 关闭selinux查看selinux是否关闭 12[linco@linco-centos7 ~]$ getenforceEnforcing # 未关闭 设置临时关闭： 1setenforce 0 # 临时关闭 永久关闭： 12345678sudo vi /etc/sysconfig/selinux# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled # 修改为disabled 1.3 关闭 swap不关闭则k8s关闭过程会报错 临时关闭： 1sudo swapoff -a 永久关闭： 12345678910111213[linco@linco-centos73 ~]$ vi /etc/fstab## /etc/fstab# Created by anaconda on Tue Mar 31 21:42:56 2020## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/centos-root / xfs defaults 0 0UUID=218a58f8-c80e-4720-a454-a4982a7a261b /boot xfs defaults 0 0#/dev/mapper/centos-swap swap swap defaults 0 0 #注释掉此行~ 1.4 配置ip_forward转发修改ip_forward配置文件，0表示禁止数据包转发，将其修改为1表示允许 1echo \"1\" &gt; /proc/sys/net/ipv4/ip_forward 更新yum源下载Centos7的源和Docker源 12345678cd /etc/yum.repos.d #进到yum源目录ll # 查看当前源#下载所需源wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repowget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 配置K8S源： 1234567[root@linco-centos7 yum.repos.d]# cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo&gt; [kubernetes]&gt; name=Kubernetes&gt; baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64&gt; enabled=1&gt; gpgcheck=0&gt; EOF 刷新yum缓存： 1yum clean all &amp;&amp; yum makecache fast 2.安装环境2.1 安装Docker,使用版本18.09.9如果已经安装可跳过此步骤 1yum install docker-ce-18.09.9 docker-ce-cli-18.09.9 containerd.io -y k8s 运行要求docker 的–cgroup-driver=systemd 1234567sudo vi /etc/docker/daemon.json&#123; \"registry-mirrors\": [\"https://xxxxx.mirror.aliyuncs.com\"], \"exec-opts\":[\"native.cgroupdriver=systemd\"]&#125; 启动docker 并设置开机自启动 1systemctl enable docker &amp;&amp; systemctl start docker 2.2 安装K8S组件1sudo yum install -y kubelet-1.16.4 kubeadm-1.16.4 kubectl-1.16.4 设置开机启动： 1systemctl enable kubelet &amp;&amp; systemctl start kubelet 添加kubectl上下文到环境中： 1234[linco@linco-centos7 ~]$ echo \"source &lt;(kubectl completion bash)\" &gt;&gt; ~/.bash_profile[linco@linco-centos7 ~]$ cd ~[linco@linco-centos7 ~]$ source .bash_profile#在home目录中，配置生效 内核参数修改： k8s 网络一般使用flannel，该网络需要设置内核参数bridge-nf-call-iptables=1添加参数配置文件： 12345sudo vi /etc/sysctl.d/k8s.conf#添加配置如下net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1 执行： 1sudo sysctl -p /etc/sysctl.d/k8s.conf 至此，环境准备安装工作完成！ Master 节点初始化1sudo kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.16.4 --pod-network-cidr=10.244.0.0/16 执行成功如图： 根据提示执行以下三条命令： 123[linco@linco-centos73 ~]$ mkdir -p $HOME/.kube[linco@linco-centos73 ~]$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config[linco@linco-centos73 ~]$ sudo chown $(id -u):$(id -g) $HOME/.kube/config 添加flannel 的网络:&emsp;&emsp;按照提示，我们需要为k8s配置一个pod network。由于国内网络不通的原因，此操作可能无法完成。我们可以使用定制的文件kube-flannel.yml来完成，上传文件到你的系统后，使用下面命令： 1kubectl apply -f kube-flannel.yml 查看集群： 123[linco@linco-centos73 ~]$ kubectl get nodesNAME STATUS ROLES AGE VERSIONlinco-centos73 Ready master 16m v1.16.4 work 节点初始化&emsp;&emsp;在要加入的工作节点机器上，执行master 初始化时提示的join 语句，即加到master 的管辖内 1sudo kubeadm join 192.168.31.223:6443 --token 27qxe5.ye0jtk7o01miijma --discovery-token-ca-cert-hash sha256:227e470a2e1cdf2ad3a13923184a04db937bf78d419e44f54fd49464a72e7cd3 查看集群： 12345[linco@linco-centos73 ~]$ kubectl get nodesNAME STATUS ROLES AGE VERSIONlinco-centos7 Ready &lt;none&gt; 119s v1.16.4linco-centos72 Ready &lt;none&gt; 21h v1.16.4linco-centos73 Ready master 21h v1.16.4","categories":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://linco.com/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Docker","slug":"Docker","permalink":"http://linco.com/tags/Docker/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}]},{"title":"Docker Swarm 基本使用","slug":"docker Swarm基本使用","date":"2020-04-04T13:53:34.077Z","updated":"2020-04-06T15:40:58.694Z","comments":true,"path":"2020/04/04/docker Swarm基本使用/","link":"","permalink":"http://linco.com/2020/04/04/docker%20Swarm%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Swarm 简介&emsp;&emsp;Swarm 是Docker 官方提供的一款集群管理工具，其主要作用是把若干台Docker 主机抽象为一个整体。Docker Swarm 提供了标准的 Docker API，所有任何已经与 Docker 守护程序通信的工具都可以使用 Swarm 轻松地扩展到多个主机。 &emsp;&emsp;Swarm 和 Kubernetes 比较类似，但是更加轻，具有的功能也较 kubernetes 更少一些。 &emsp;&emsp;Swarm 集群由管理节点（manager）和工作节点（work node）构成。如下图所示：swarm mananger：负责整个集群的管理工作包括集群配置、服务管理等所有跟集群有关的工作。work node：即图中的 available node，主要负责运行相应的服务来执行任务（task）。 &emsp;&emsp;当你创建一个service 时，你定义了它的理想状态（副本数、网络、存储资源、对外暴露的端口等）。Docker 会维持它的状态，例如，如果一个worker node 不可用了，Docker会调度不可用node 的task 到其他nodes 上。 Swarm 环境搭建及初始化准备三台互通的机器(此处用的是虚拟机)： 宿主机名称 IP 备注 linco-centos7 192.168.31.221 manager linco-centos72 192.168.31.222 work node linco-centos73 192.168.31.223 work node 在manager主机上执行以下命令创建管理节点1docker swarm init --advertise-addr 192.168.31.221 运行结果如下： 1234567Swarm initialized: current node (kj8wmkf6mcbayasj8zqkdclht) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-5u4ik4lp7b0riq5nejhvflbp84s1uhi6kpnmgf7o50ouq8prg0-dudp3uo991c6ladck13eydxbj 192.168.31.221:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 在其他子节点上执行以下命令添加工作节点到集群1docker swarm join --token SWMTKN-1-5u4ik4lp7b0riq5nejhvflbp84s1uhi6kpnmgf7o50ouq8prg0-dudp3uo991c6ladck13eydxbj 192.168.31.221:2377 结果： 1This node joined a swarm as a worker. 如果出现如下错误，则需要打开2377端口，具体可参考linux使用firewall打开端口 Error response from daemon: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = &quot;transport: Error while dialing dial tcp 192.168.31.221:2377: connect: no route to host&quot;在manager主机上运行 docker node ls,可以看到其他两个节点已经成功加入12345[linco@linco-centos7 ~]$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONkj8wmkf6mcbayasj8zqkdclht * linco-centos7 Ready Active Leader 18.09.9kwys625i3mkxd1vo0z2r4z0fi linco-centos72 Ready Active 18.09.9npupwq5ee8dnmlejxmfa6mou6 linco-centos73 Ready Active 18.09.9 部署Docker 应用（此处以Nginx为例）&emsp;&emsp;Swarm 环境搭建好之后，整个工作节点集群，都可以当作一个宿主机来操作了。可以在manager 上进行各种服务的部署管理 创建服务运行以下命令，创建一个nginx 集群，3 台机器 1docker service create --name nginx --replicas 3 -p 80:80 nginx:1.7.9 执行docker service ls命令，可以查看服务列表： 123[linco@linco-centos7 ~]$ docker service lsID NAME MODE REPLICAS IMAGE PORTSt6fh31u0erwy nginx replicated 3/3 nginx:1.7.9 *:80-&gt;80/tcp 执行docker service ps [服务名] 可以查看服务详情： 12345[linco@linco-centos7 ~]$ docker service ps nginxID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSzq8zhhu8h6ir nginx.1 nginx:1.7.9 linco-centos72 Running Running about a minute ago 8sv070ql676r nginx.2 nginx:1.7.9 linco-centos73 Running Running about a minute ago qvwhdpibe151 nginx.3 nginx:1.7.9 linco-centos7 Running Running about a minute ago 访问服务，任何一台主机ip都可以访问到： 服务维护&emsp;&emsp;服务集群运行后，会以期望的状态方式管理整个集群。如，刚刚创建的3 中nginx 组成的集群。如果其中一台宕机，swarm 会自动新建一台，来补足task 数量. 在一个节点机器上，删除一个容器: 12[linco@linco-centos73 ~]$ docker rm -fv 6340d500893c6340d500893c 在管理节点上查询可以看到，又新启了一台服务 123456[linco@linco-centos7 ~]$ docker service ps nginxID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSzq8zhhu8h6ir nginx.1 nginx:1.7.9 linco-centos72 Running Running 28 minutes ago wu3hnwbzees1 nginx.2 nginx:1.7.9 linco-centos73 Running Running 47 seconds ago 8sv070ql676r \\_ nginx.2 nginx:1.7.9 linco-centos73 Shutdown Failed 53 seconds ago \"task: non-zero exit (137)\" qvwhdpibe151 nginx.3 nginx:1.7.9 linco-centos7 Running Running 27 minutes ago 滚动升级更新原来的nginx 版本为1.9.7 1docker service update --image nginx:1.9.7 nginx 更新之后查看服务，可以看到版本已经升级了: 123[linco@linco-centos7 ~]$ docker service lsID NAME MODE REPLICAS IMAGE PORTSt6fh31u0erwy nginx replicated 3/3 nginx:1.9.7 *:80-&gt;80/tcp 动态扩容服务还可以动态在节点集群上进行扩容 1docker service scale nginx=4 再次查看，发现服务已经变为四个节点了 12345678910[linco@linco-centos7 ~]$ docker service ps nginxID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSxrv33gu16lmc nginx.1 nginx:1.9.7 linco-centos72 Running Running 3 minutes ago zq8zhhu8h6ir \\_ nginx.1 nginx:1.7.9 linco-centos72 Shutdown Shutdown 4 minutes ago x1o334p47add nginx.2 nginx:1.9.7 linco-centos73 Running Running 5 minutes ago wu3hnwbzees1 \\_ nginx.2 nginx:1.7.9 linco-centos73 Shutdown Shutdown 6 minutes ago 8sv070ql676r \\_ nginx.2 nginx:1.7.9 linco-centos73 Shutdown Failed 8 minutes ago \"task: non-zero exit (137)\" mwkvokgc6nod nginx.3 nginx:1.9.7 linco-centos7 Running Running 4 minutes ago qvwhdpibe151 \\_ nginx.3 nginx:1.7.9 linco-centos7 Shutdown Shutdown 5 minutes ago wnvqmydgh1ax nginx.4 nginx:1.9.7 linco-centos7 Running Running 12 seconds ago 停止服务使用下面命令和停止对应服务 123docker service rm hellos或docker service scale hellos=0 网络通讯swarm 管理的集群，内部建立一个统一的网络层,你绑定的端口，并非是直接绑定到宿主机，而是绑在这个overlay 网络。对于集群来说，相当于都绑在网络的一个端口上，启用负载策略来转发请求，如下图:","categories":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://linco.com/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Docker","slug":"Docker","permalink":"http://linco.com/tags/Docker/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}]},{"title":"Dockerfile 相关命令详解","slug":"dockerfile相关命令详解","date":"2020-03-30T12:08:59.605Z","updated":"2020-03-30T15:26:50.515Z","comments":true,"path":"2020/03/30/dockerfile相关命令详解/","link":"","permalink":"http://linco.com/2020/03/30/dockerfile%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"Dockerfile&emsp;&emsp;镜像是多层存储，每一层是在前一层的基础上进行的修改；而容器同样也是多层存储，是在以镜像为基础层，在其基础上加一层作为容器运行时的存储层。 &emsp;&emsp;Dockerfile 是一个文本文件，其内包含了一条条的 指令(Instruction)，每一条指令构建镜像的一层，因此每一条指令的内容，就是描述该镜像层应当如何构建。 Dockerfile的基本结构：&emsp;&emsp;Dockerfile 一般分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令，’#’ 为 Dockerfile 中的注释。 Docker 命令详解 FROM 指定基础镜像一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。格式： 1234FROM &lt;image&gt;FROM &lt;image&gt;:&lt;tag&gt;FROM &lt;image&gt;@&lt;digest&gt;#tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像 示例： FROM nginx:latestMAINTAINER 维护者信息，可选格式： 1MAINTAINER &lt;name&gt; 示例： MAINTAINER ColinLinRUN 执行命令RUN用于在镜像容器中执行命令，其有以下两种命令执行方式：shell 格式： 1RUN &lt;命令&gt; #就像直接在命令行中输入的命令一样。 示例： RUN apt-get update exec 格式： 1RUN [\"可执行文件\", \"参数1\", \"参数2\"] #这更像是函数调用中的格式。 示例： RUN [&quot;/etc/execfile&quot;, &quot;arg1&quot;, &quot;arg1&quot;]注：如果需要将两条命令或者多条命令联合起来执行需要加上&amp;，例如：cd /usr/local/src &amp;&amp; wget xxxxxxx COPY 复制文件RUN 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用 12COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径&gt;... &lt;目标路径&gt;COPY [--chown=&lt;user&gt;:&lt;group&gt;] [\"&lt;源路径1&gt;\",... \"&lt;目标路径&gt;\"] COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置。示例： COPY package.json /usr/src/app/&lt;源路径&gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match 规则。示例： COPY hom* /mydir/ COPY hom?.txt /mydir/&lt;目标路径&gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 ADD 更高级的复制文件ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。ADD命令会将tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget,而copy则不能。 示例： ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /注：在 Docker 官方的 Dockerfile 最佳实践文档 中要求，尽可能的使用 COPY，因为 COPY 的语义很明确，就是复制文件而已，而 ADD 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 ADD 的场合，就是所提及的需要自动解压缩的场合。 CMD 容器启动命令，也就是构建容器后才调用CMD 指令的格式和 RUN 相似，也是两种格式： shell 格式： 1CMD &lt;命令&gt; exec 格式： 12CMD [\"可执行文件\", \"参数1\", \"参数2\"...]#参数列表格式：CMD [\"参数1\", \"参数2\"...]。在指定了 ENTRYPOINT 指令后，用 CMD 指定具体的参数。 注：当运行container 的时候声明了command，则不再用image 中的CMD 默认所定义的命令。一个Dockerfile 中只能有一个有效的CMD，当定义多个CMD 的时候，只有最后一个才会起作用 ENTRYPOINTENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式 ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 –entrypoint 来指定。 当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： 1&lt;ENTRYPOINT&gt; \"&lt;CMD&gt;\" 关于 ENTRYPOINT CMD的使用场景，可以参考gitbooks 注：ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT。Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令。 ENV 设置环境变量格式： 12ENV &lt;key&gt; &lt;value&gt; #&lt;key&gt;之后的所有内容均会被视为其&lt;value&gt;的组成部分，因此，一次只能设置一个变量ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;...#可以设置多个变量，每个变量为一个\"&lt;key&gt;=&lt;value&gt;\"的键值对，如果&lt;key&gt;中包含空格，可以使用\\来进行转义，也可以通过\"\"来进行标示；另外，反斜线也可以用于续行 示例： ENV MY_NAME Colin Lin ENV VERSION=1.0 DEBUG=on \\ NAME=&quot;Happy Feet&quot;ARG 用于指定传递给构建运行时的变量Dockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 –build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖。 格式： 1ARG &lt;参数名&gt;[=&lt;默认值&gt;] 示例： ARG build_user=wwwVOLUME 定义匿名卷（指定持久化目录）格式： 12VOLUME [\"&lt;路径1&gt;\", \"&lt;路径2&gt;\"...]VOLUME &lt;路径&gt; 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能：1 卷可以容器间共享和重用2 容器并不一定要和其它容器共享卷3 修改卷后会立即生效4 对卷的修改不会对镜像产生影响5 卷会一直存在，直到没有任何容器在使用它 示例： VOLUME /data 这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如：docker run -d -v mydata:/data xxxx在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置。 EXPOSE 暴露端口格式： 1EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]。 EXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来。-p，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。 WORKDIR 指定工作目录使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。格式： 1WORKDIR &lt;工作目录路径&gt;。 USER 指定当前用户格式： 1USER &lt;用户名&gt;[:&lt;用户组&gt;] USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER 则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。注：USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。 示例： RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis USER redis RUN [ &quot;redis-server&quot; ]如果以 root 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用 su 或者 sudo，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 gosu。示例： # 建立 redis 用户，并使用 gosu 换另一个用户执行命令 RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis # 下载 gosu RUN wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64&quot; \\ &amp;&amp; chmod +x /usr/local/bin/gosu \\ &amp;&amp; gosu nobody true # 设置 CMD，并以另外的用户执行 CMD [ &quot;exec&quot;, &quot;gosu&quot;, &quot;redis&quot;, &quot;redis-server&quot; ]HEALTHCHECK 健康检查格式： 12HEALTHCHECK [选项] CMD &lt;命令&gt; #设置检查容器健康状况的命令HEALTHCHECK NONE #如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令 当在一个镜像指定了 HEALTHCHECK 指令后，用其启动容器，初始状态会为 starting，在 HEALTHCHECK 指令检查成功后变为 healthy，如果连续一定次数失败，则会变为 unhealthy HEALTHCHECK 支持下列选项：–interval=&lt;间隔&gt;：两次健康检查的间隔，默认为 30 秒；–timeout=&lt;时长&gt;：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒；–retries=&lt;次数&gt;：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。和 CMD, ENTRYPOINT 一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 示例： FROM nginx RUN apt-get update &amp;&amp; apt-get install -y curl &amp;&amp; rm -rf /var/lib/apt/lists/* HEALTHCHECK --interval=5s --timeout=3s \\ CMD curl -fs http://localhost/ || exit 1ONBUILD 为他人做嫁衣裳格式： 1ONBUILD &lt;其它指令&gt;。 ONBUILD 是一个特殊的指令，它后面跟的是其它指令，比如 RUN, COPY 等，而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行。","categories":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://linco.com/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Docker","slug":"Docker","permalink":"http://linco.com/tags/Docker/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}]},{"title":"docker 容器内部安装 vim","slug":"docker 容器内部安装 vim","date":"2020-03-27T16:25:00.787Z","updated":"2020-03-28T11:39:16.597Z","comments":true,"path":"2020/03/28/docker 容器内部安装 vim/","link":"","permalink":"http://linco.com/2020/03/28/docker%20%E5%AE%B9%E5%99%A8%E5%86%85%E9%83%A8%E5%AE%89%E8%A3%85%20vim/","excerpt":"","text":"Docker 容器内部默认是没有按准vim的，如果我们需要在docker容器内部使用vim, 可以通过以下方式安装： 1、首先执行以下命令，更新安装源： 1apt-get update 2、再执行以下命令安装vim即可： 1apt-get install vim","categories":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://linco.com/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Docker","slug":"Docker","permalink":"http://linco.com/tags/Docker/"},{"name":"后端","slug":"后端","permalink":"http://linco.com/tags/%E5%90%8E%E7%AB%AF/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}]},{"title":"Linux 查看内存及CPU使用情况","slug":"Linux 内存相关知识","date":"2020-03-27T12:07:07.659Z","updated":"2020-03-28T11:32:15.811Z","comments":true,"path":"2020/03/27/Linux 内存相关知识/","link":"","permalink":"http://linco.com/2020/03/27/Linux%20%E5%86%85%E5%AD%98%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/","excerpt":"","text":"方式一：单独查看内存使用情况的命令1free -选项 选项：&emsp;&emsp;-b：以Byte为单位显示内存使用情况；&emsp;&emsp;-k：以KB为单位显示内存使用情况；&emsp;&emsp;-m：以MB为单位显示内存使用情况；&emsp;&emsp;-o：不显示缓冲区调节列；&emsp;&emsp;-s&lt;间隔秒数&gt;：持续观察内存使用状况；&emsp;&emsp;-t：显示内存总和列；&emsp;&emsp;-V：显示版本信息。 实例： 1234[linco@linco-centos7 ~]$ free -m total used free shared buff/cache availableMem: 991 224 166 6 599 604Swap: 2047 1 2046 其中第一列解释如下：&emsp;&emsp;Mem 内存的使用信息&emsp;&emsp;Swap 交换空间的使用信息 第一行解释如下：&emsp;&emsp;total：系统总的可用物理内存大小；&emsp;&emsp;used：已被使用的物理内存大小；&emsp;&emsp;free：空闲的物理内存大小；&emsp;&emsp;shared：当前已经废弃不用；&emsp;&emsp;buff/cache：被 buffer 和 cache 使用的物理内存大小；&emsp;&emsp;available：还可以被 应用程序 使用的物理内存大小&emsp;&emsp;其中total = used + free free 与 available 的区别：free 是真正尚未被使用的物理内存数量。available 是应用程序认为可用内存数量，available = free + buffer + cache (注：只是大概的计算方法) buff/cache 清理：&emsp;&emsp;Linux服务器运行一段时间后，由于其内存管理机制，会将暂时不用的内存转为buff/cache，这样在程序使用到这一部分数据时，能够很快的取出，从而提高系统的运行效率，所以这也正是linux内存管理中非常出色的一点，所以乍一看内存剩余的非常少，但是在程序真正需要内存空间时,也就是free内存不够时，linux内核就会回收 buffer 和 cache 的内存让出给程序使用，这样达到对内存的最充分利用，所以真正剩余的内存是free+buff/cache。 &emsp;&emsp;但是有些时候大量的缓存占据空间，这时候应用程序回去使用swap交换空间，从而使系统变慢，这时候需要手动去释放内存，释放内存的时候，首先执行命令 sync 将所有正在内存中的缓冲区写到磁盘中，其中包括已经修改的文件inode、已延迟的块I/O以及读写映射文件，从而确保文件系统的完整性。[sync命令的作用] 1234567#先执行syncsync#再根据自己需求选择以下命令执行echo 1 &gt; /proc/sys/vm/drop_caches #表示清除pagecache。 echo 2 &gt; /proc/sys/vm/drop_caches #表示清除回收slab分配器中的对象（包括目录项缓存和inode缓存）。slab分配器是内核中管理内存的一种机制，其中很多缓存数据实现都是用的pagecache。 echo 3 &gt; /proc/sys/vm/drop_caches #表示清除pagecache和slab分配器中的缓存对象，即所有缓存。 &emsp;&emsp;如果执行以上echo x &gt; … 提示没有权限，我们除了加sudo之外还需要使用 “sh -c” 命令,它可以让 bash 将一个字串作为完整的命令来执行。&emsp;&emsp;因为重定向符号 “&gt;” 也是 bash 的命令。如果仅用“ sudo echo 1 &gt; /proc/sys/vm/drop_caches”只是让 echo 命令具有了 root 权限，但是没有让 “&gt;” 命令也具有root 权限，所以 bash 会认为这个命令没有写入信息的权权限。参考 正确做法如下： 12345sudo sh -c \"echo 1 &gt; /proc/sys/vm/drop_caches\"sudo sh -c \"echo 2 &gt; /proc/sys/vm/drop_caches\"sudo sh -c \"echo 3 &gt; /proc/sys/vm/drop_caches\" Swap 交换分区：&emsp;&emsp;交换空间是现代Linux系统中的第二种内存类型。交换空间的主要功能是当实际内存被填满，需要更多的空间时，用磁盘空间代替RAM内存。可以在常规文件系统或逻辑卷上使用一个或多个专用交换分区或交换文件。 如何为swap交换分区扩容：增加交换分区一般有两种方法，第一种是系统安装时进行设置的。方法1：使用分区：在安装OS时划分出专门的交换分区，空间大小要事先规划好，启动系统时自动进行mount。这种方法只能在安装OS时设定，一旦设定好不容易改变，除非重装系统。方法2：使用swapfile：步骤：1、创建swapfile：root权限下，创建swapfile，假设当前目录为”/“,执行如下命令： 12 dd if=/dev/zero of=swapfile bs=1024 count=128000#在根目录下创建了一个swapfile,名称为“swapfile”，大小为128M，也可以把文件输出到自己想要的任何目录中，放在根目录下比较好，不容易误破坏，放在其他目录下则不然了； 命令中选项解释：if：即输入文件,input file，of：即输出文件,output file，dev/zero：是Linux的一种特殊字符设备(输入设备)，可以用来创建一个指定长度用于初始化的空文件，如临时交换文件，该设备无穷尽地提供0，可以提供任何你需要的数目；bs=1024 ：单位数据块（block）同时读入/输出的块字节大小为1024 个字节即1KB；count=128000 ：数据块（block）数量为128000 ，即128000个1KB。（dd命令里的单位M表示1024*1024,k表示1024）。 2、将swapfile设置为swap空间 1mkswap swapfile 3、启用交换空间： 1swapon swapfile 至此增加交换空间的操作结束了，可以使用free命令查看swap空间大小是否发生变化；4、如果不再使用空间可以选择关闭交换空间: 1swapoff swapfile 使用这种方法在每次系统启动时都需要手动设置、开启swapfile，比较麻烦，解决方法：在 /etc/rc.d/rc.local 文件的末行下追加加以下内容：/sbin/swapon /swapfile保存后退出，这样在系统启动后，swap空间就会自动加载了。 方式二：查看内存及cpu使用情况的命令：1top 方式三：安装htop工具，查看更直观安装命令如下： 123456#Ubuntu 使用 apt-get 安装sudo apt-get install htop#Centos7 使用yum安装sudo yum -y install epel-release #先增加一个第三方的源，名字叫：EPELsudo yum -y install htop 安装完后，直接输入命令： 1htop 即可看到如下信息：","categories":[{"name":"Linux","slug":"Linux","permalink":"http://linco.com/categories/Linux/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://linco.com/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Docker","slug":"Docker","permalink":"http://linco.com/tags/Docker/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"http://linco.com/categories/Linux/"}]},{"title":"Centos7 安装指定版本 Docker","slug":"centos7安装docker","date":"2020-03-26T13:09:56.873Z","updated":"2020-04-04T13:43:32.005Z","comments":true,"path":"2020/03/26/centos7安装docker/","link":"","permalink":"http://linco.com/2020/03/26/centos7%E5%AE%89%E8%A3%85docker/","excerpt":"","text":"卸载旧版本12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine Docker 默认安装1$ yum -y install docker # 默认安装最新版本 Docker安装指定版本安装所需软件包yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。 123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 使用yum-config-manager 添加docker仓库123$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 执行以下命令，列出 docker 所有可用版本1$ yum list docker-ce --showduplicates | sort -r 根据自己选择特定版本号的docker安装$ sudo yum install docker-ce- docker-ce-cli- containerd.io 例如： 1sudo yum install docker-ce-18.09.9 docker-ce-cli-18.09.9 containerd.io -y 启动 Docker 并且配置 开机自启动12$ sudo systemctl start docker$ sudo systemctl enable docker 配置阿里云镜像加速自行注册阿里云账号，获取自己的镜像加速地址：https://cr.console.aliyun.com/cn-hongkong/instances/mirrors 解决普通用户（非root)无权限使用docker命令问题docker进程使用Unix Socket而不是TCP端口。而默认情况下，Unix socket属于root用户，需要root权限才能访问。为了方便普通用户每次执行docker不需要加sudo,我们可以用以下方法给普通用户授权： docker守护进程启动的时候，会默认赋予名字为docker的用户组读写Unix socket的权限，因此只要创建docker用户组，并将当前用户加入到docker用户组中，那么当前用户就有权限访问Unix socket了，进而也就可以执行docker相关命令。 1234sudo groupadd docker #添加docker用户组sudo gpasswd -a $USER docker #将登陆用户加入到docker用户组中newgrp docker #更新用户组docker ps #测试docker命令是否可以使用sudo正常使用 Docker - Compose 安装从 Github 上下载它的二进制包来使用，最新发行的版本地址：https://github.com/docker/compose/releases。运行以下命令下载到usr/local/bin目录下： 1curl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 在国内通过curl有时经常超时，这时我们可以直接到github上找到我们的对应的版本下载二进制文件到本地，将其重命名为docker-compose , 并上传到/usr/local/bin 目录下。例如：https://github.com/docker/compose/releases/download/1.25.4/docker-compose-Linux-x86_64 运行以下命名，使下载的二进制文件具有可执行权限： 1sudo chmod +x /usr/local/bin/docker-compose 结束语Centos7 安装 Docker 就此完成，感谢支持！","categories":[{"name":"Linux","slug":"Linux","permalink":"http://linco.com/categories/Linux/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://linco.com/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Docker","slug":"Docker","permalink":"http://linco.com/tags/Docker/"},{"name":"后端","slug":"后端","permalink":"http://linco.com/tags/%E5%90%8E%E7%AB%AF/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"http://linco.com/categories/Linux/"}]},{"title":"Mybatis 入门","slug":"mybatis入门01","date":"2020-03-20T07:25:40.122Z","updated":"2020-03-20T16:32:15.138Z","comments":true,"path":"2020/03/20/mybatis入门01/","link":"","permalink":"http://linco.com/2020/03/20/mybatis%E5%85%A5%E9%97%A801/","excerpt":"","text":"Mybatis简介MyBatis 前身是iBatis,其源于“Internet”和“ibatis”的组合， 是一款优秀的持久层框架，它支持自定义SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。 其本质是一种半自动的ORM 框架，除了POJO 和映射关系之外，还需要编写SQL 语句；Mybatis 映射文件三要素：SQL、映射规则和POJO为什么需要ORM框架传统的JDBC 编程存在的弊端: - 工作量大，操作数据库至少要5步； - 业务代码和技术代码耦合； - 连接资源手动关闭，带来了隐患。入门导入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.4&lt;/version&gt;&lt;/dependency&gt; 创建Mybatis配置文件文件名：mybatis-config.xml, 以下主要列出mybatis配置文件的顶层结构，详细配置可参考:mybatis.org 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=\"1.0\" encoding=\"ISO-8859-1\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!--properties属性配置--&gt; &lt;properties/&gt; &lt;!--设置--&gt; &lt;settings/&gt; &lt;!--类型别名，类型别名可为 Java 类型设置一个缩写名字。 它仅用于 XML 配置，意在降低冗余的全限定类名书写。--&gt; &lt;typeAliases/&gt; &lt;!--类型处理器--&gt; &lt;typeHandlers/&gt; &lt;!-- 对象工厂--&gt; &lt;objectFactory&gt; &lt;!-- 插件 --&gt; &lt;plugins）/&gt; &lt;!--environments 元素定义了如何配置环境。--&gt; &lt;environments default=\"development\"&gt; &lt;environment/&gt; &lt;!-- 事务管理器 --&gt; &lt;transactionManager/&gt; &lt;!--数据源--&gt; &lt;dataSource&gt; &lt;/environments&gt; &lt;!-- 映射器 --&gt; &lt;mappers&gt; &lt;mapper resource=\"sqlmapper/UserMapper.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 创建 Java Bean 实体类12345678910package com.colin.mybatisdemo.entiry;public class User &#123; private Integer id; private String userName; private String mobile;&#125; 创建 Mapper 接口跟Mapper xml 文件映射 1234567package com.colin.mybatisdemo.mapper;import com.colin.mybatisdemo.entiry.User;public interface UserMapper &#123; User getOneById(int id);&#125; 创建 Mapper xml 映射文件123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.colin.mybatisdemo.mapper.UserMapper\"&gt; &lt;select id=\"getOneById\" resultType=\"User\"&gt; SELECT * from USER where id = #&#123;id, jdbcType=INTEGER&#125;; &lt;/select&gt;&lt;/mapper&gt; &emsp;&emsp;MyBatis 的真正强大在于它的语句映射，这是它的魔力所在。由于它的异常强大，映射器的 XML 文件就显得相对简单。如果拿它跟具有相同功能的 JDBC 代码进行对比，你会立即发现省掉了将近 95% 的代码。MyBatis 致力于减少使用成本，让用户能更专注于 SQL 代码。 &emsp;&emsp;SQL 映射文件只有很少的几个顶级元素（按照应被定义的顺序列出）： cache – 该命名空间的缓存配置。 cache-ref – 引用其它命名空间的缓存配置。 resultMap – 描述如何从数据库结果集中加载对象，是最复杂也是最强大的元素。 parameterMap – 老式风格的参数映射。此元素已被废弃，并可能在将来被移除！请使用行内参数映射。文档中不会介绍此元素。 sql – 可被其它语句引用的可重用语句块。 insert – 映射插入语句。 update – 映射更新语句。 delete – 映射删除语句。 select – 映射查询语句。 具体使用详解可参考：[mybatis.org](https://mybatis.org/mybatis-3/zh/sqlmap-xml.html)创建一个测试类-快速入门12345678910111213141516171819202122232425262728public class UserMapperTest &#123; private SqlSessionFactory sqlSessionFactory; @Before public void testBefore() throws IOException &#123; //--------------------第一阶段--------------------------- // 1.读取mybatis配置文件创SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); // 1.读取mybatis配置文件创SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); inputStream.close(); &#125; @Test public void testGetOneById()&#123; //--------------------第二阶段--------------------------- // 2.获取sqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); // 3.获取对应mapper UserMapper userMapper = sqlSession.getMapper(UserMapper.class); //--------------------第三阶段--------------------------- // 4.执行查询语句并返回单条数据 User user = userMapper.getOneById(1); System.out.println(user.getUserName() + \":\" + user.getMobile()); &#125;&#125; 结束语Mybatis 入门介绍就讲到这里了，博客Demo源码请访问：mybatis-demo","categories":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"博客","slug":"博客","permalink":"http://linco.com/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"MyBatis","slug":"MyBatis","permalink":"http://linco.com/tags/MyBatis/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://linco.com/categories/%E5%90%8E%E7%AB%AF/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-03-19T15:11:45.272Z","updated":"2020-03-28T11:39:08.605Z","comments":true,"path":"2020/03/19/hello-world/","link":"","permalink":"http://linco.com/2020/03/19/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"前端","slug":"前端","permalink":"http://linco.com/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[],"keywords":[{"name":"前端","slug":"前端","permalink":"http://linco.com/categories/%E5%89%8D%E7%AB%AF/"}]}]}